测试 extract_arxiv_id 函数：
--------------------------------------------------
测试 1:
输入: arXiv:1810.04805
提取的 arXiv ID: 1810.04805
--------------------------------------------------
测试 2:
输入: arXiv 1810.04805
提取的 arXiv ID: 1810.04805
--------------------------------------------------
测试 3:
输入: https://arxiv.org/abs/1810.04805
提取的 arXiv ID: 1810.04805
--------------------------------------------------
测试 4:
输入: arXiv:1810.04805.
提取的 arXiv ID: 1810.04805
--------------------------------------------------
测试 5:
输入: arXiv 1810.04805.
提取的 arXiv ID: 1810.04805
--------------------------------------------------
测试 6:
输入: https://arxiv.org/abs/1810.04805.
提取的 arXiv ID: 1810.04805
--------------------------------------------------
测试 7:
输入: Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv:1810.04805.
提取的 arXiv ID: 1810.04805
--------------------------------------------------
测试 8:
输入: Strubell, E., Ganesh, A., & McCallum, A. (2019). Energy and Policy Considerations for Deep Learning in NLP. arXiv:1906.02243.
提取的 arXiv ID: 1906.02243
--------------------------------------------------
